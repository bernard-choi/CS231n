{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/36406676/52783613-c8490600-3095-11e9-8c80-cf62ec321b03.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fully connected Layer는 마지막 단에서 최종목표를 수행하는 Layer.(Classifying, Regression...)\n",
    "\n",
    "\n",
    "- 32 X 32 X 3의 이미지가 있으면 1X3072로 펼친다.\n",
    "\n",
    "\n",
    "- 최종 class개수가 10개 이므로 weight는 3072 X 10으로 만들어 둔 뒤에 input과 weight를 곱하여 10개의 output을 만들어낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 합성곱계층(Concolutional Layer)에서는 합성곱 연산을 처리합니다. 합성곱 연산은 이미지 처리에서 말하는 필터연산을 의미합니다.\n",
    "\n",
    "\n",
    "\n",
    "- 합성곱 연산은 입력 데이터(32 X 32 X 3) 에 필터(5 X 5 X 3)를 적용합니다. 합성곱 연산은 필터의 윈도우를 일정 간격으로 이동해가며 입력 데이터에 적용합니다.\n",
    "\n",
    "\n",
    "\n",
    "- 입력과 필터에서 대응하는 원소끼리 곱한 후 그 총합을 구합니다.(Wx + b) 그리고 그 결과를 출력의 해당 장소에 저장."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/36406676/52784061-3641fd00-3097-11e9-8c4d-b278929bf67b.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하나하나 다 곱해주면 28 X 28 X 1 크기의 output이 나옵니다.이 output은 activation map이라고 해서 사진이 가지는 특징을 나타내어 줍니다.\n",
    "\n",
    "\n",
    "- CNN을 사용할때는 filter를 하나만 사용하지 않습니다. 다양한 필터를 사용하여 필터마다 다른 특징을 나타나게 만드는것.(Blur, Sharp,..). 이 값도 학습의 대상이 되어서 목적(task)를 주면 그에 최적화된 parameter가 저장된다.\n",
    "\n",
    "\n",
    "- CNN은 local feature, position invariant한 특징을 갖는데 이 conv layer때문이다. filter의 크기 만큼의 정보만 추출하고, 똑같은 좌표가 이동하면서 적용되기 때문에 영상의 여러군데서 나타나는 정보들을 하나로 통합해서 보게된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/36406676/52784645-20353c00-3099-11e9-98bc-0d984a61c5a2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예를 들어 6개의 필터를 추출한다면 28X28X1의 activation map이 6개가 쌓이므로 28X28X6이 된다.\n",
    "\n",
    "\n",
    "- 합성곱의 개념은 블록으로 이해하면 쉽다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/36406676/52902740-4b19be80-3258-11e9-8d26-e215323aa5f5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/36406676/52902741-50770900-3258-11e9-9f14-edb640e98f4d.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/36406676/52785131-94241400-309a-11e9-8b1a-96369a51d6a3.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "- conv layer를 여려겹 겹치면서 반복하게 될 것이다.\n",
    "\n",
    "\n",
    "- filter의 depth(channel)은 input의 channel과 같아야 한다. 예를 들어 아래 이미지에서 28X28X6의 이미지에 필터를 씌우려면 가로 세로 길이는 임의로 정하면 될 것이고 깊은 6이여야 합니다. input의 깊이가 6이기 때문입니다.\n",
    "\n",
    "\n",
    "- 28X28X6의 이미지에 5X5X6의 필터가 10개가 들어간다면 activation map의 크기는 24X24X10이 될것입니다. 필터1번에 activation map 1겹이 쌓이게 됩니다.\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/36406676/52785333-0dbc0200-309b-11e9-88bc-9c2416d4c8d0.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "input 데이터에 필터를 적용하려면 필터가 적용되는 부분을 일자로 펴서 wx+b하기 좋게 만들어줘야한다. 이러한 기능을 하는 함수 img2col을 만들어주었다.\n",
    "\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution을 정의하기 전에 im2col이라는 함수 생성\n",
    "# im2col은 입력 데이터를 필터링 하기 좋게 전개하는 함수.\n",
    "# 3차원 입력 데이터에 im2col을 적용하면 2차원 행렬로 바뀝니다.\n",
    "\n",
    "#img2col\n",
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"다수의 이미지를 입력받아 2차원 배열로 변환한다(평탄화).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : 4차원 배열 형태의 입력 데이터(이미지 수, 채널 수, 높이, 너비)\n",
    "    filter_h : 필터의 높이\n",
    "    filter_w : 필터의 너비\n",
    "    stride : 스트라이드\n",
    "    pad : 패딩\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    col : 2차원 배열\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/36406676/52911283-fbcd9f80-32e4-11e9-8c33-cb0a991fc5e5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/36406676/52911295-1c95f500-32e5-11e9-8ea6-4fe46a7510fe.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n",
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "# 실제로 사용\n",
    "x1 = np.random.rand(1,3,7,7) #(데이터 수, 채널 수 , 높이, 너비)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad = 0)\n",
    "print(col1.shape) # stride 1이므로 3 X 3 = 9, 5X5X3 = 75 . 9번의 행렬곱이 이뤄져야함.\n",
    "x2 = np.random.rand(10,3,7,7)\n",
    "col2 = im2col(x2, 5, 5, stride = 1, pad = 0)\n",
    "print(col2.shape) # stride 1, 데이터 수 10개   3X3X10 = 90 , 5X5X3 = 75 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv Layer도 구현해보았다. 아래 사진 내용을 직접 대입해보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self,w,b,stride=1, pad= 0):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "    \n",
    "        \n",
    "        #중간 데이터 (backward시 사용)\n",
    "        self.x = None\n",
    "        self.col = None\n",
    "        self.col_w = None\n",
    "        \n",
    "        # 가중치와 편향 매개변수의 기울기\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "    \n",
    "    def forward(self,x):\n",
    "        FN, C, FH, FW = self.w.shape # FN:  필터개수, C: 채널수, FH: 필터높이. FW:필터너비\n",
    "        N, C, H, W = x.shape # N개의 데이터\n",
    "        out_h = int(1+(H+ 2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1+(W+ 2*self.pad - FW) / self.stride) # im2col로 펴진 데이터를 reshape위해\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.w.reshape(FN, -1).T # 필터전개\n",
    "        out = np.dot(col,col_W) + self.b # (28X28, 6) = (784,6)\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0,3,1,2) # (N, H, W, C) -> (N, C, H, W)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        FN, C, FH, FW = self.w.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1,FN)\n",
    "        \n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dw = np.dot(self.col.T, dout)\n",
    "        self.dw = self.dw.transpose(1,0).reshape(FN, C, FH, FW)\n",
    "        \n",
    "        dcol = np.dot(dout, self.col_W.T)\n",
    "        dx = col2im(dcol, self.s.shape, FH, FW, self.stride, self.pad)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/36406676/52162205-9f2e8a00-2713-11e9-94e9-8984011f972a.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random.randn으로 w,b,x 임의로 지정, batch_size = 1\n",
    "x = np.random.rand(1, 3, 32, 32)  # 32X32X3 input에 5X5X3의 필터를 대입\n",
    "w = np.random.rand(6, 3, 5, 5)    # filter 수 6개\n",
    "b = np.random.rand(784,6)         # output size가 28X28 = 784 \n",
    "\n",
    "conv = Convolution(w,b)\n",
    "conv.forward(x).shape             # (1,6,28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stride\n",
    "\n",
    "- 아래와 같이 7X7 input에 3X3 filter를 적용하고 싶다면 위아래로 이동해야되는데 이동하는 stepsize가 stride입니다. stride가 1이면 오른쪽으로 한칸 씩 다섯번 이동할 것이고 아래쪽으로 한칸씩 다섯번 이동할 것입니다. \n",
    "\n",
    "\n",
    "- 이를 수식으로 정리하면 output size : **(N-F) / stride + 1 **\n",
    "\n",
    "\n",
    "- stride = 2일 경우 output size는? (7-3)/2 +1 = 3이므로 3X3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/36406676/52786445-30034f00-309e-11e9-844c-8c3320261309.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeropad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하지만 stride가 3인 경우 나누어 떨어지지 않는다. (N-F)/stride +1 = 3/4 +1이 된다. 이경우 zero padding을 이용한다. padding이란 이미지의 가장자리 부분에 어떠한 숫자들을 채워 넣는 것을 의미한다. 가장자리에 0을 넣은 것을 zero padding이라고 한다. \n",
    "\n",
    "\n",
    "- 공식은 **(N-F+2P)/stride +1** 이 된다. P는 zero padding의 수\n",
    "\n",
    "\n",
    "- 보통 패딩은 filter_size가 FXF일때  (F-1)/2 만큼 준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/36406676/52787019-f3385780-309f-11e9-9c65-3f55fdcfbc0c.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 그림에서 F=3(pad=1), F=5(pad=2), F=7(pad=3)의 output_size도 직접 구해보았다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/36406676/52167071-c0fe3000-2758-11e9-829f-6b0c74d50b53.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6, 7, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 이번에는 padding을 입혀보자\n",
    "\n",
    "x = np.random.rand(1,3,7,7)\n",
    "w = np.random.rand(6,3,3,3) # 6 filter 3X3 filter\n",
    "b = np.random.rand(49,6)      \n",
    "conv = Convolution(w,b,pad=1)       \n",
    "conv.forward(x).shape # 7x7 output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6, 7, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 다른것도 해보자.\n",
    "x2 = np.random.rand(1,3,7,7)\n",
    "w2 = np.random.rand(6,3,5,5) # 6filter 5X5 filter\n",
    "b2 = np.random.rand(49,6)      \n",
    "conv2 = Convolution(w2,b2,pad=2)  \n",
    "conv2.forward(x2).shape # 7x7 output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6, 7, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 다른것도 해보자.\n",
    "x3 = np.random.rand(1,3,7,7)\n",
    "w3 = np.random.rand(6,3,7,7) # 6filter 7X7 filter\n",
    "b3 = np.random.rand(49,6)      \n",
    "conv3 = Convolution(w3,b3,pad=3)  \n",
    "conv3.forward(x3).shape # 7x7 output!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "패딩을 하는 또 다른 이유는 input의 크기를 보전하는대도 있습니다. \n",
    "\n",
    "convolution의 과정에서 사진의 크기를 그대로 유지시켜 주는 역할을 padding이 해줍니다.\n",
    "\n",
    "다음 퀴즈를 풀어봅시다. 직접 구해보았습니다.\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/36406676/52787577-a5bcea00-30a1-11e9-85d5-55628767b51f.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 32, 32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## input volume: 32X32X3 filter 5*5\n",
    "x4 = np.random.rand(1,3,32,32)\n",
    "w4 = np.random.rand(10,3,5,5)               # 10개의 5X5 filter\n",
    "b4 = np.random.rand(1024,10)                # 32X32 = 1024(filter_size 32x32) \n",
    "conv4 = Convolution(w4,b4,pad=2, stride=1)  \n",
    "conv4.forward(x4).shape                     # (1,10,32,32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "32 X 32 X 3의 input 이미지 그리고 filter size 는 5 X 5 X 10.filter가 10개.\n",
    "\n",
    "output size는 (32-5+2*2)/1 +1 = 32 즉 **32 X 32 X 10**\n",
    "\n",
    "Conv Layer를 거쳤지만 사진의 크기가 그대로 유지되었습니다. 이것이 패딩을 하는 이유\n",
    "\n",
    "그렇다면 위의 layer에서 parameter의 개수는 몇개나 될까요??? \n",
    "\n",
    "**5 X 5 X 3 + 1(bias) X 10 = 760**입니다.\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/36406676/52788144-655e6b80-30a3-11e9-94d3-fbedaf68e93d.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "지금까지 한 내용들을 정리해 보겠습니다. \n",
    "\n",
    "W1 X H1 X D1의 크기인 input이 있고(W=가로, H =세로, D = 깊이) \n",
    "\n",
    "k는 필터의 개수, 필터size인 F(FXF), S는 stride의 크기, P는 padding의 수이다. 이 필터가 적용되면 output size는 \n",
    "\n",
    "\n",
    "__W2 = (W1 - F + 2XP)/S +1__\n",
    "\n",
    "__H2 = (H2 - F + 2XP)/S +1__\n",
    "\n",
    "__D2 = K__ 인 output값 W2 X H2 X D2가 만들어집니다.\n",
    "\n",
    "그리고 parameter의 개수는 __(F\\*F\\*D1)\\*K +K__ 가 될 것입니다.\n",
    "\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "- Convolutional layer parameter에 대한 설정 tip\n",
    "\n",
    "filter 개수는 2의 n승(ex. 32, 64, 128, 512...)\n",
    "\n",
    "filter 가로(세로)길이 = 3, stride =1, zero pad = 1\n",
    "\n",
    "filter 가로(세로)길이 = 5, stride =1, zero pad = 2\n",
    "\n",
    "filter 가로(세로)길이 = 5, stride =2, zero pad = ? (맞는거 아무거나)\n",
    "\n",
    "filter 가로(세로)길이 = 3, stride =1, zero pad = 0\n",
    "\n",
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/36406676/52788806-67292e80-30a5-11e9-91b0-073dcbbe0c61.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 사진은 filter의 크기가 1X1 인 경우로 W, H는 그대로 유지되고 Depth만 축소됩니다. \n",
    "\n",
    "padding이 없어도 크기가 그대로 유지되며 activation map도 아무런 탈도 없이 나옵니다.\n",
    "\n",
    "이러한 F=1을 사용하는 Convnet을 다음장(9장) 에서 배운다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layer\n",
    "convolutional layer와 relu function을 거친 뒤, 처리와 관리를 쉽게 하도록 만들어주는 것이 pooling layer. Downsampling 이라고도 볼 수 있다. \n",
    "\n",
    "아래 사진을 보면 224의 filter_size가 112로 줄어든 것 확인\n",
    "\n",
    "conv layer가 쌓이면 activation의 깊이가 깊어져서 224\\*224\\*64같은 크기의 이미지가 만들어지고 계산량이 많아진다. 따라서 pooling을 해서 activation map의 크기를 반으로 팍 줄여준다면 계산도 두 배 빨라질 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/36406676/52789163-7361bb80-30a6-11e9-850e-08559f14eeaa.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "풀링의 가장 대표적인 방법으로는 MAXPOOLING이 있습니다. \n",
    "\n",
    "우선 pooling layer의 filter를 준비합니다. 이때 주의할점은 이 filter에는 parameter들이 없습니다. 아래 예에서 4\\*4 크기의 사진에 2\\*2크기의 filter로, stride는 2로 pooling을 합니다.\n",
    "\n",
    "그리고 fitler를 convolution 하듯이 이미지에다가 max연산을 해줍니다. 예를 들면 빨간 부분안에서 가장 큰 6값만 남겨지고 나머지는 지웁니다. 그 다음 stride가 2이므로 오른쪽으로 두 칸 움직여서 다시 초록색부분에서 가장 큰 값인 8만 남겨두고 다 지웁니다.\n",
    "\n",
    "여기서 주의해야 할 점은 일반적으로 stride는 filter끼리 겹치는 것을 지양해야 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/36406676/52173225-8f6e7e80-27c3-11e9-878a-f0a7a35c0b23.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride = 1, pad = 0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape # (batchsize, colour, height, weight)\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        #전개 (1)\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        \n",
    "        #최댓값(2)\n",
    "        out = np.max(col, axis=1)\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0,3,1,2)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, x):\n",
    "        dout = dout.transpose(0,2,3,1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, self.s.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 그림대로  따라해봄\n",
    "x = np.array([[[[1,1,2,4],\n",
    "                [5,6,7,8],\n",
    "                [3,2,1,0],\n",
    "                [1,2,3,4]]]])\n",
    "\n",
    "Pool = Pooling(2,2,stride=2) \n",
    "Pool.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.41884088,  1.15983335],\n",
       "         [ 1.99876974, -0.22019957]],\n",
       "\n",
       "        [[ 1.29151128,  1.14541837],\n",
       "         [ 1.35793363,  0.54427693]],\n",
       "\n",
       "        [[ 0.8756976 ,  0.62052864],\n",
       "         [ 2.57428995,  0.7788195 ]]]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randn(1,3,4,4)\n",
    "Pool = Pooling(2,2,stride=2) \n",
    "Pool.forward(x) # 2X2가 depth 인 3만큼 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple Convnet을 구현해봄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim=(1, 28, 28),\n",
    "                 conv_param={'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},              # Conv layer는 30X5X5의 filter, pad는 0, stride=1의 과정을 거친다.\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "        \n",
    "        self.params = {\n",
    "            'W1': weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size),\n",
    "            'b1': np.zeros(filter_num),\n",
    "            'W2': weight_init_std * np.random.randn(pool_output_size, hidden_size),\n",
    "            'b2': np.zeros(hidden_size),\n",
    "            'W3': weight_init_std * np.random.randn(hidden_size, output_size),\n",
    "            'b3': np.zeros(output_size),\n",
    "        }\n",
    "        \n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],                       # Conv - Pool - FC - FC의 단계를 거침\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)                                   # Pooling의 filter_size는 2X2 , stride는 2\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1:\n",
    "            t = np.argmax(t, axis=1)\n",
    "            \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt)\n",
    "            \n",
    "        return acc / x.shape[0]\n",
    "    \n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "            \n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        self.loss(x, t)\n",
    "\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        grads = {\n",
    "            'W1': self.layers['Conv1'].dW,\n",
    "            'b1': self.layers['Conv1'].db,\n",
    "            'W2': self.layers['Affine1'].dW,\n",
    "            'b2': self.layers['Affine1'].db,\n",
    "            'W3': self.layers['Affine2'].dW,\n",
    "            'b3': self.layers['Affine2'].db,\n",
    "        }\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def save_params(self, file_name='params.pkl'):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name='params.pkl'):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# if you want to reduce training time, apply following lines.\n",
    "x_train = x_train[:5000]\n",
    "t_train = t_train[:5000]\n",
    "x_test = x_test[:1000]\n",
    "t_test = t_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2995731609903176\n",
      "=== epoch:1, train acc:0.223, test acc:0.197 ===\n",
      "train loss:2.2969068238454633\n",
      "train loss:2.292434397173415\n",
      "train loss:2.2854925535874178\n",
      "train loss:2.27490929461273\n",
      "train loss:2.266689276941388\n",
      "train loss:2.2669428702039927\n",
      "train loss:2.248037432034485\n",
      "train loss:2.226887780492325\n",
      "train loss:2.2080510662512736\n",
      "train loss:2.1736515465778075\n",
      "train loss:2.126932162280348\n",
      "train loss:2.103144222055123\n",
      "train loss:2.0587359987048526\n",
      "train loss:2.001569781615461\n",
      "train loss:1.9363298946922223\n",
      "train loss:1.7673470029529674\n",
      "train loss:1.8032646809871629\n",
      "train loss:1.77526206612391\n",
      "train loss:1.6616556572498298\n",
      "train loss:1.6114805424625935\n",
      "train loss:1.4169475618058829\n",
      "train loss:1.4212768711279977\n",
      "train loss:1.2815824564074838\n",
      "train loss:1.2283695657740141\n",
      "train loss:1.1590456353665288\n",
      "train loss:1.029974848252532\n",
      "train loss:1.006837707656893\n",
      "train loss:0.9172189970478394\n",
      "train loss:0.9914255228465175\n",
      "train loss:0.978259520707926\n",
      "train loss:0.7780486914101309\n",
      "train loss:0.7599510196166743\n",
      "train loss:0.6769680140023424\n",
      "train loss:0.7623920382313725\n",
      "train loss:0.68483913951842\n",
      "train loss:0.714081058095956\n",
      "train loss:0.6908937548838371\n",
      "train loss:0.681113864289891\n",
      "train loss:0.5012864419997599\n",
      "train loss:0.6956378875975993\n",
      "train loss:0.6188831524681843\n",
      "train loss:0.5671243770255093\n",
      "train loss:0.5020368644582244\n",
      "train loss:0.4093793029565266\n",
      "train loss:0.6454610791733728\n",
      "train loss:0.6312895499297907\n",
      "train loss:0.3942009775656515\n",
      "train loss:0.4267772917594384\n",
      "train loss:0.633031432088808\n",
      "train loss:0.6331319913211969\n",
      "=== epoch:2, train acc:0.816, test acc:0.801 ===\n",
      "train loss:0.6557823710570614\n",
      "train loss:0.4238513060612138\n",
      "train loss:0.617062510540274\n",
      "train loss:0.40010659239800433\n",
      "train loss:0.4837082512029089\n",
      "train loss:0.47548539923579336\n",
      "train loss:0.643335068598154\n",
      "train loss:0.4592242801522199\n",
      "train loss:0.49534485641306913\n",
      "train loss:0.3181045896228751\n",
      "train loss:0.407335984363483\n",
      "train loss:0.4563892608391126\n",
      "train loss:0.6378111633894478\n",
      "train loss:0.506778302595112\n",
      "train loss:0.5936522673345628\n",
      "train loss:0.5106511739242007\n",
      "train loss:0.4652260311428858\n",
      "train loss:0.6376619806886581\n",
      "train loss:0.4988738801641053\n",
      "train loss:0.5628712597217619\n",
      "train loss:0.4399200018449763\n",
      "train loss:0.44304587303087684\n",
      "train loss:0.4261914414171424\n",
      "train loss:0.3804943531397612\n",
      "train loss:0.4809036405734058\n",
      "train loss:0.39081407469994306\n",
      "train loss:0.4527099010060322\n",
      "train loss:0.5184803100268208\n",
      "train loss:0.3588201063914161\n",
      "train loss:0.6119728873266168\n",
      "train loss:0.3841652473213143\n",
      "train loss:0.398240921817061\n",
      "train loss:0.42913064596688116\n",
      "train loss:0.20502169276706575\n",
      "train loss:0.28677056285042524\n",
      "train loss:0.3683573937144641\n",
      "train loss:0.2960846989296232\n",
      "train loss:0.44526476143144145\n",
      "train loss:0.40826511757950246\n",
      "train loss:0.21056234773588983\n",
      "train loss:0.19432592234076065\n",
      "train loss:0.316291073905111\n",
      "train loss:0.300884247658993\n",
      "train loss:0.37313605677745054\n",
      "train loss:0.40258467648781265\n",
      "train loss:0.25721055960692113\n",
      "train loss:0.21769304192196604\n",
      "train loss:0.5168782432262381\n",
      "train loss:0.3542316350365653\n",
      "train loss:0.4510111723384966\n",
      "=== epoch:3, train acc:0.872, test acc:0.855 ===\n",
      "train loss:0.2272870862770486\n",
      "train loss:0.3074010419723941\n",
      "train loss:0.28839411599089343\n",
      "train loss:0.4855960060307323\n",
      "train loss:0.2245278959164936\n",
      "train loss:0.27439930689072184\n",
      "train loss:0.5643309110852021\n",
      "train loss:0.3162821232209809\n",
      "train loss:0.38752123213555106\n",
      "train loss:0.15827410970044054\n",
      "train loss:0.3353500824224808\n",
      "train loss:0.24061338624858414\n",
      "train loss:0.23926251012022617\n",
      "train loss:0.4236213523592991\n",
      "train loss:0.2210850136395813\n",
      "train loss:0.2582087120238579\n",
      "train loss:0.31047465233105936\n",
      "train loss:0.3850544750418808\n",
      "train loss:0.3600908648579291\n",
      "train loss:0.22936275865580416\n",
      "train loss:0.26688455638567\n",
      "train loss:0.2752526409469897\n",
      "train loss:0.3249466471674792\n",
      "train loss:0.22508180402952413\n",
      "train loss:0.3183477676727313\n",
      "train loss:0.3191544015466844\n",
      "train loss:0.24298066500288645\n",
      "train loss:0.31878515873346097\n",
      "train loss:0.2387006915740338\n",
      "train loss:0.2823923715888215\n",
      "train loss:0.34807686328541204\n",
      "train loss:0.2428791425860507\n",
      "train loss:0.419120955458622\n",
      "train loss:0.21172652743808915\n",
      "train loss:0.14685977434525455\n",
      "train loss:0.380112205481908\n",
      "train loss:0.27606892946884487\n",
      "train loss:0.3009347093162064\n",
      "train loss:0.18807428759799735\n",
      "train loss:0.23202849291667055\n",
      "train loss:0.4402942018085034\n",
      "train loss:0.2891265975578791\n",
      "train loss:0.42836489886730805\n",
      "train loss:0.1625463041203665\n",
      "train loss:0.21563147733150348\n",
      "train loss:0.30781179695885896\n",
      "train loss:0.3106099625059804\n",
      "train loss:0.2460146121753249\n",
      "train loss:0.23426272674368925\n",
      "train loss:0.27223542104161846\n",
      "=== epoch:4, train acc:0.891, test acc:0.89 ===\n",
      "train loss:0.28846269035252914\n",
      "train loss:0.2525374406077294\n",
      "train loss:0.3008181238927135\n",
      "train loss:0.3145370286209016\n",
      "train loss:0.326976359595399\n",
      "train loss:0.2748363151143875\n",
      "train loss:0.20137942408611426\n",
      "train loss:0.3597046489714904\n",
      "train loss:0.23937974561900702\n",
      "train loss:0.3552110105233519\n",
      "train loss:0.3937184085171392\n",
      "train loss:0.2093830687773311\n",
      "train loss:0.1948502135362562\n",
      "train loss:0.31864054820331295\n",
      "train loss:0.2835838158710315\n",
      "train loss:0.25616200954036483\n",
      "train loss:0.18805926670490172\n",
      "train loss:0.34906451995696147\n",
      "train loss:0.23875491029004198\n",
      "train loss:0.3388443141398074\n",
      "train loss:0.4881569305720892\n",
      "train loss:0.29044941221329035\n",
      "train loss:0.23210150561923157\n",
      "train loss:0.16570252072909908\n",
      "train loss:0.3765167794709904\n",
      "train loss:0.1992545312827228\n",
      "train loss:0.21073985841181664\n",
      "train loss:0.20317605433694527\n",
      "train loss:0.25527279606186903\n",
      "train loss:0.1917118581740697\n",
      "train loss:0.5760265370856006\n",
      "train loss:0.17187085116069628\n",
      "train loss:0.36258438129112264\n",
      "train loss:0.2161671388636517\n",
      "train loss:0.34166103976600276\n",
      "train loss:0.16627557320269556\n",
      "train loss:0.18170242546902543\n",
      "train loss:0.21218460506707065\n",
      "train loss:0.1673978282478864\n",
      "train loss:0.2125513906001616\n",
      "train loss:0.2538975381133377\n",
      "train loss:0.20951686350844487\n",
      "train loss:0.21268485382626387\n",
      "train loss:0.40170280986061646\n",
      "train loss:0.2183865967143937\n",
      "train loss:0.1988963158650889\n",
      "train loss:0.19341662779067056\n",
      "train loss:0.2749934748873667\n",
      "train loss:0.18250973549704422\n",
      "train loss:0.26169039036390435\n",
      "=== epoch:5, train acc:0.905, test acc:0.908 ===\n",
      "train loss:0.2072746418981113\n",
      "train loss:0.2593452780658806\n",
      "train loss:0.2452009278149706\n",
      "train loss:0.2214808909638461\n",
      "train loss:0.2153933181424619\n",
      "train loss:0.2593833938114509\n",
      "train loss:0.18024353621801315\n",
      "train loss:0.32002031385766605\n",
      "train loss:0.19176551179140625\n",
      "train loss:0.4661835197691282\n",
      "train loss:0.296932646953585\n",
      "train loss:0.20287681112979927\n",
      "train loss:0.2882017217844369\n",
      "train loss:0.17405976678959156\n",
      "train loss:0.23931021342842662\n",
      "train loss:0.30641904455443897\n",
      "train loss:0.19665685374095498\n",
      "train loss:0.15625181545916836\n",
      "train loss:0.21304658102200846\n",
      "train loss:0.24791773555835278\n",
      "train loss:0.24658473145014984\n",
      "train loss:0.11094592078462295\n",
      "train loss:0.3046006509656502\n",
      "train loss:0.13642827969061977\n",
      "train loss:0.31792175994177746\n",
      "train loss:0.16223817203164548\n",
      "train loss:0.14900800449535181\n",
      "train loss:0.17913686462874803\n",
      "train loss:0.30365524297761426\n",
      "train loss:0.22436468923285116\n",
      "train loss:0.11532030678267699\n",
      "train loss:0.17675106926529605\n",
      "train loss:0.09803948285075395\n",
      "train loss:0.1951316047823159\n",
      "train loss:0.1377277919169308\n",
      "train loss:0.120444222934017\n",
      "train loss:0.1851943142587207\n",
      "train loss:0.1909056614733452\n",
      "train loss:0.09008765095818379\n",
      "train loss:0.12419826219306537\n",
      "train loss:0.16674896720271257\n",
      "train loss:0.2960775448555932\n",
      "train loss:0.2990815881784096\n",
      "train loss:0.2520270381560931\n",
      "train loss:0.22455093510859933\n",
      "train loss:0.3684056692705351\n",
      "train loss:0.2873962616630676\n",
      "train loss:0.14918404871221125\n",
      "train loss:0.32785327004014\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.906\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 5\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1, 28, 28),\n",
    "                        conv_param={'filter_num': 30,\n",
    "                                    'filter_size': 5,\n",
    "                                    'pad': 0,\n",
    "                                    'stride': 1,\n",
    "                                   }\n",
    "                       )\n",
    "\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000,\n",
    "                 )\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

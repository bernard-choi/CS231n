{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "- Linear Data\n",
    "- Linear Model\n",
    "- y = 2x + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  \"\"\"\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## 2. Generate Data\n",
    "num_data = 1000\n",
    "num_epoch = 1000\n",
    "\n",
    "noise = init.normal(torch.FloatTensor(num_data,1), std=1)\n",
    "x = init.uniform(torch.Tensor(num_data,1),-10,10)\n",
    "y = 2*x + 3\n",
    "y_noise = 2*x + 3 + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.1062],\n",
      "        [ 5.9726],\n",
      "        [ 3.1783],\n",
      "        [-1.2058],\n",
      "        [ 2.7071],\n",
      "        [-9.3741],\n",
      "        [ 9.8333],\n",
      "        [ 5.1304],\n",
      "        [-2.7297],\n",
      "        [-1.0847]])\n",
      "tensor([[ 14.2146],\n",
      "        [ 15.2463],\n",
      "        [ 11.3008],\n",
      "        [ -0.8887],\n",
      "        [  7.5799],\n",
      "        [-15.6744],\n",
      "        [ 21.6731],\n",
      "        [ 12.8840],\n",
      "        [ -3.7747],\n",
      "        [  1.3390]])\n"
     ]
    }
   ],
   "source": [
    "print(x[:10])\n",
    "print(y_noise[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1,1)\n",
    "output = model(Variable(x))\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(194.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(19.5667, grad_fn=<MseLossBackward>)\n",
      "tensor(9.2342, grad_fn=<MseLossBackward>)\n",
      "tensor(8.1020, grad_fn=<MseLossBackward>)\n",
      "tensor(7.5258, grad_fn=<MseLossBackward>)\n",
      "tensor(7.0202, grad_fn=<MseLossBackward>)\n",
      "tensor(6.5550, grad_fn=<MseLossBackward>)\n",
      "tensor(6.1257, grad_fn=<MseLossBackward>)\n",
      "tensor(5.7294, grad_fn=<MseLossBackward>)\n",
      "tensor(5.3637, grad_fn=<MseLossBackward>)\n",
      "tensor(5.0262, grad_fn=<MseLossBackward>)\n",
      "tensor(4.7146, grad_fn=<MseLossBackward>)\n",
      "tensor(4.4271, grad_fn=<MseLossBackward>)\n",
      "tensor(4.1617, grad_fn=<MseLossBackward>)\n",
      "tensor(3.9168, grad_fn=<MseLossBackward>)\n",
      "tensor(3.6907, grad_fn=<MseLossBackward>)\n",
      "tensor(3.4820, grad_fn=<MseLossBackward>)\n",
      "tensor(3.2894, grad_fn=<MseLossBackward>)\n",
      "tensor(3.1117, grad_fn=<MseLossBackward>)\n",
      "tensor(2.9476, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7962, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6564, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5274, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4084, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2985, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1971, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1034, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0170, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9373, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8637, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7958, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7331, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6752, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6218, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5725, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5270, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4850, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4462, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4105, grad_fn=<MseLossBackward>)\n",
      "tensor(1.3774, grad_fn=<MseLossBackward>)\n",
      "tensor(1.3470, grad_fn=<MseLossBackward>)\n",
      "tensor(1.3188, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2929, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2689, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2468, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2264, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2075, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1902, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1741, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1593, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1456, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1330, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1214, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1106, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1007, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0915, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0831, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0753, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0681, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0614, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0553, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0496, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0444, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0396, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0351, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0310, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0272, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0237, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0205, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0175, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0148, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0099, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0077, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0057, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0039, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9992, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9978, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9966, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9955, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9944, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9934, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9925, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9917, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9910, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9902, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9896, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9890, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9884, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9879, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9875, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9870, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9866, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9863, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9859, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9856, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9853, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9850, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss_arr = []\n",
    "label = Variable(y_noise)\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(Variable(x))\n",
    "    \n",
    "    loss = loss_func(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 ==0:\n",
    "        print(loss)\n",
    "        \n",
    "    loss_arr.append(loss.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.9880]]) tensor([2.9709])\n"
     ]
    }
   ],
   "source": [
    "param_list = list(model.parameters())\n",
    "print(param_list[0].data, param_list[1].data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
